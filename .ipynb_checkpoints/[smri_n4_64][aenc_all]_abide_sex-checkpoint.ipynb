{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing experiment configs\n",
    "import yaml\n",
    "from box import Box\n",
    "from comet_ml import Experiment\n",
    "\n",
    "with open(\"configs/configs_abideI_n4.yml\", \"r\") as ymlfile:\n",
    "    cfg = Box(yaml.safe_load(ymlfile))\n",
    "\n",
    "with open(\"configs/general_args.yml\", \"r\") as ymlfile:\n",
    "    general_args = yaml.safe_load(ymlfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ffk_08tbgIoA",
    "outputId": "bc619b1c-3ad4-4eb0-9eaf-b68d9a9ca778"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/kondratevakate/fader-net-abide/ad45028bcac5484babc77a4eec1a742f\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an experiment with your api key\n",
    "experiment = Experiment(\n",
    "    api_key = cfg.logging.comet_experiment_api,\n",
    "    project_name = cfg.logging.comet_project_name,\n",
    "    workspace = cfg.logging.comet_workspace,\n",
    ")\n",
    "\n",
    "experiment_name = f\"aenc_{cfg.params.args.conv_model[-1]}_{cfg.params.args.learning_rate}_{cfg.params.n_sites}_sites/seed_{cfg.params.r_seed}\" \n",
    "experiment.set_name(experiment_name)\n",
    "experiment.log_dataset_info(cfg.params.dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing utils for training, logging and viz\n",
    "\n",
    "from models import *\n",
    "from viz import *\n",
    "from utils import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "import torch \n",
    "save_folder = cfg.logging.weights_save_folder\n",
    "selected_all_sum_tensor = torch.load(cfg.inputs.data)\n",
    "\n",
    "if len(selected_all_sum_tensor.size()) < 5:\n",
    "    selected_all_sum_tensor = selected_all_sum_tensor.unsqueeze(1).float()\n",
    "\n",
    "selected_targets_tensor = torch.load(cfg.inputs.targets)\n",
    "selected_sites_tensor = torch.load(cfg.inputs.sites)\n",
    "selected_sexes_tensor = torch.load(cfg.inputs.sex)\n",
    "selected_ages_tensor = torch.load(cfg.inputs.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a training dataset with N_sites parametr from configs\n",
    "n_sites = cfg.params.n_sites\n",
    "site_codes = cfg.params.site_codes\n",
    "code2site = {i : s for s, i in site_codes.items()}\n",
    "site_labels = [code2site[i] for i in range(1, n_sites + 1)]\n",
    "\n",
    "# manially cropping data to cubic format\n",
    "### this should be manually corrected for each dataset used\n",
    "img_crop = range(cfg.params.img_crop[0], cfg.params.img_crop[1])\n",
    "selected_all_sum_tensor = selected_all_sum_tensor[..., :, img_crop, :]\n",
    "selected_all_sum_tensor = torch.nn.functional.pad(selected_all_sum_tensor, pad=tuple(cfg.params.pad))\n",
    "# asserting if shape mismatch\n",
    "assert selected_all_sum_tensor.size()[2:] != cfg.params.img_size , f'Input shape is {selected_all_sum_tensor.size()[2:]},  doesnt match {cfg.params.img_size}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding site names to use it as One Hot Encoded vectore while training\n",
    "selected_sites_tensor_ohe = []\n",
    "for v in selected_sites_tensor.unique():\n",
    "    selected_sites_tensor_ohe.append((selected_sites_tensor == v).float())\n",
    "selected_sites_tensor_ohe = torch.stack(selected_sites_tensor_ohe, dim=-1)\n",
    "\n",
    "selected_sexes_tensor_ohe = []\n",
    "for v in selected_sexes_tensor.unique():\n",
    "    selected_sexes_tensor_ohe.append((selected_sexes_tensor == v).float())\n",
    "selected_sexes_tensor_ohe = torch.stack(selected_sexes_tensor_ohe, dim=-1)\n",
    "\n",
    "# Choosing top `n_sites` by size in dataset\n",
    "selected_attrs_tensor = selected_sites_tensor_ohe[:, :n_sites]\n",
    "selected_idx = selected_attrs_tensor.sum(axis=1).byte()\n",
    "\n",
    "# Normalizing input vector prior to training\n",
    "selected_all_sum_tensor = selected_all_sum_tensor - selected_all_sum_tensor.mean()\n",
    "selected_all_sum_tensor = selected_all_sum_tensor/selected_all_sum_tensor.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a random state and args\n",
    "\n",
    "import random, numpy\n",
    "r_seed = cfg.params.r_seed\n",
    "random.seed(r_seed)\n",
    "numpy.random.seed(r_seed)\n",
    "torch.manual_seed(r_seed)\n",
    "torch.cuda.manual_seed(r_seed)\n",
    "\n",
    "args = {k : v for k, v in general_args.items()}\n",
    "args.update(cfg.params.args)\n",
    "# Updating variables to tuples and lists, after *yml read\n",
    "args.update({'img_shape': tuple(args['img_shape'])})\n",
    "args.update({'noises': list(np.zeros_like(\n",
    "    list(args['conv_model'])))})\n",
    "args.update({'n_attrs_outputs': [selected_attrs_tensor.size(1)]})\n",
    "# args.update({'n_epochs': 10})\n",
    "experiment.log_parameters(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s0I6YkxuKgyf",
    "outputId": "c9f949fc-e063-4f69-92e0-2b04618c9f4d"
   },
   "outputs": [],
   "source": [
    "# wriring dataloader for training on selected data\n",
    "tensor_dataset = data.TensorDataset(selected_all_sum_tensor[selected_idx], \n",
    "                                    selected_targets_tensor[selected_idx],\n",
    "                                    selected_attrs_tensor[selected_idx])\n",
    "idx = np.arange(len(tensor_dataset))\n",
    "train_idx = idx\n",
    "val_idx = idx\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    data.Subset(tensor_dataset, train_idx), batch_size=args[\"batch_size\"], shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    data.Subset(tensor_dataset, val_idx), batch_size=args[\"batch_size\"], shuffle=False)\n",
    "# set target for domain classification\n",
    "AE, D, AE_opt, D_opt = create_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "train_stats = train_fadernet_sched(\n",
    "                             train_loader, val_loader, args, \n",
    "                             AE, D, AE_opt, D_opt, device, \n",
    "                             AE_crit=nn.MSELoss(), \n",
    "                             D_crit=nn.BCEWithLogitsLoss(),\n",
    "                             score_freq=cfg.params.save_vis_freq, \n",
    "                             vis_freq=cfg.params.save_vis_freq, \n",
    "                             site_labels=site_labels,\n",
    "                             save_freq=cfg.params.save_vis_freq,\n",
    "                             experiment_name = experiment_name,\n",
    "    experiment = experiment,\n",
    "    save_folder= cfg.logging.weights_save_folder) "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6EPH6Ww5g3Xf",
    "1yHuT5C4ulia"
   ],
   "name": "[progress-sched][abide1_reho][fader-7] abide_summaries.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
